{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d319219a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "def read_conll_data(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        sentences, labels = [], []\n",
    "        sentence, label = [], []\n",
    "\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    labels.append(label)\n",
    "                    sentence, label = [], []\n",
    "            else:\n",
    "                token, tag = line.split()\n",
    "                sentence.append(token)\n",
    "                label.append(tag)\n",
    "\n",
    "        if sentence:\n",
    "            sentences.append(sentence)\n",
    "            labels.append(label)\n",
    "    return sentences, labels\n",
    "\n",
    "tokens, ner_tags = read_conll_data(\"amharic_ner_labels.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8517d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "\n",
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name, num_labels=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d21f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "dataset = Dataset.from_dict({\n",
    "    'tokens': tokens,\n",
    "    'ner_tags': ner_tags\n",
    "})\n",
    "\n",
    "label_list = list(set(tag for label in ner_tags for tag in label))\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5423cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokenized_inputs = tokenizer(example['tokens'], truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "    prev_word_id = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id is None:\n",
    "            labels.append(-100)\n",
    "        elif word_id != prev_word_id:\n",
    "            labels.append(label2id[example['ner_tags'][word_id]])\n",
    "        else:\n",
    "            labels.append(label2id[example['ner_tags'][word_id]])\n",
    "        prev_word_id = word_id\n",
    "\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_and_align_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf352003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    num_train_epochs=4,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10874b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0111962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = trainer.evaluate()\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ba816",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"amharic-ner-model\")\n",
    "tokenizer.save_pretrained(\"amharic-ner-model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
